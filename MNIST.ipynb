{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3y1O03owRzY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoWB_jomI7CZ"
      },
      "source": [
        "\n",
        "Handwritten Digit Recognition Using PyTorch â€” Intro To Neural Networks\n",
        "\n",
        "transforms.ToTensor = converts the image into numbers that are understanble by system\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xl_JdqAwq3O"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from torchvision import datasets , transforms\n",
        "from torch import nn , optim"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8VEALZYwrHM"
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5) , (0.5)),])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hjZpProxD_h"
      },
      "source": [
        "trainset = datasets.MNIST('/home/sujayeendra/Documents',download=True , train = True , transform=transform)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHn3uiRG0OrD"
      },
      "source": [
        "valset = datasets.MNIST('/home/sujayeendra/Documents',download = True , train = False , transform=transform)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i76Fc8kIxEH3"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset , batch_size=64 , shuffle=True)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5IA5M9KxEQ2"
      },
      "source": [
        "valloader = torch.utils.data.DataLoader(valset , batch_size=64 , shuffle=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANm5igdExEUo",
        "outputId": "4b417e5e-4540-4f4f-cf64-6f56454730bb"
      },
      "source": [
        "#Knowing the data\n",
        "dataiter = iter(trainloader)\n",
        "images , labels = dataiter.next()\n",
        "print(images.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "bbRy3A_fxEbL",
        "outputId": "e1a1ca5c-976c-42ae-c896-02a8a6a8596b"
      },
      "source": [
        "#Display a image\n",
        "plt.imshow(images[0].numpy().squeeze(),cmap = 'gray_r')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff6a78089d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZlyvfhw39Pi"
      },
      "source": [
        "figure = plt.figure()\n",
        "num_of_images = 60\n",
        "for index in range(1 , num_of_images + 1):\n",
        "  plt.subplot(6 , 10 , index)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(images[index].numpy().squeeze() ,  cmap='gray_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRdCdD_v4s_6",
        "outputId": "07742fe4-b311-4e54-add7-1efa80b6ce7f"
      },
      "source": [
        "#Build Neural Network\n",
        "#Input Layer -> Hidden Layer -> Output Layer -> Result\n",
        "\n",
        "input_size = 784\n",
        "hidden_sizes = [128,64]\n",
        "output_size = 10\n",
        "\n",
        "model = nn.Sequential(nn.Linear(input_size , hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0] , hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1] , output_size),\n",
        "                      nn.LogSoftmax(dim = 1))\n",
        "\n",
        "print(model)\n",
        "\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (5): LogSoftmax(dim=1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OklIzHKL6xgM"
      },
      "source": [
        "criterion = nn.NLLLoss()                            #defining loss function \n",
        "images , labels = next(iter(trainloader))           #getting sample data from train loader \n",
        "images = images.view(images.shape[0] , -1)          #flattening the image to one dim\n",
        "\n",
        "logps = model(images)                               #push the data to model and log probability vector\n",
        "loss  = criterion(logps , labels)                   #calculate loss between logps and labels size= [10 , 1]\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9r3E86i8-xK",
        "outputId": "b947c5f3-5224-46b8-c140-f9c5ef85a988"
      },
      "source": [
        "#adjusting weights \n",
        "print(\"Before Backward Pass\" , model[0].weight.grad) #none \n",
        "loss.backward()                                      #calculate the gradients \n",
        "print(\"after backward pass\" , model[0].weight.grad)  #values obtained after backward pass\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Before Backward Pass None\n",
            "after backward pass tensor([[ 0.0017,  0.0017,  0.0017,  ...,  0.0017,  0.0017,  0.0017],\n",
            "        [-0.0008, -0.0008, -0.0008,  ..., -0.0008, -0.0008, -0.0008],\n",
            "        [ 0.0005,  0.0005,  0.0005,  ...,  0.0005,  0.0005,  0.0005],\n",
            "        ...,\n",
            "        [-0.0011, -0.0011, -0.0011,  ..., -0.0011, -0.0011, -0.0011],\n",
            "        [ 0.0020,  0.0020,  0.0020,  ...,  0.0020,  0.0020,  0.0020],\n",
            "        [ 0.0015,  0.0015,  0.0015,  ...,  0.0015,  0.0015,  0.0015]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdI5Y2Mx9kTi",
        "outputId": "00958280-54c9-42ed-d0c4-4ead66365c1d"
      },
      "source": [
        "optimizer = optim.SGD(model.parameters() , lr = 0.003 , momentum=0.9)\n",
        "time0 = time()\n",
        "epochs = 15\n",
        "for e in range(epochs):\n",
        "  running_loss = 0\n",
        "  for images , labels in trainloader:\n",
        "    #flatten\n",
        "    images = images.view(images.shape[0] , -1)\n",
        "    #training pass\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(images)\n",
        "    loss = criterion(output ,  labels)\n",
        "\n",
        "    #BP\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "    running_loss+=loss.item()\n",
        "  else:\n",
        "    print(\"Epoch {} -Training loss : {} \".format(e, running_loss/len(trainloader)))\n",
        "print(\"\\nTraing Time (in minutes)=\" , (time() - time0) / 60)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 -Training loss : 0.2857929187924115 \n",
            "Epoch 1 -Training loss : 0.22458157419507055 \n",
            "Epoch 2 -Training loss : 0.1820040400753588 \n",
            "Epoch 3 -Training loss : 0.1514335314808751 \n",
            "Epoch 4 -Training loss : 0.13152663369200376 \n",
            "Epoch 5 -Training loss : 0.11437831557830418 \n",
            "Epoch 6 -Training loss : 0.10117782245892515 \n",
            "Epoch 7 -Training loss : 0.0903703984824309 \n",
            "Epoch 8 -Training loss : 0.08181428565715215 \n",
            "Epoch 9 -Training loss : 0.07597598986231538 \n",
            "Epoch 10 -Training loss : 0.06771771920157839 \n",
            "Epoch 11 -Training loss : 0.06275402547181971 \n",
            "Epoch 12 -Training loss : 0.05822539836940751 \n",
            "Epoch 13 -Training loss : 0.053328013585717565 \n",
            "Epoch 14 -Training loss : 0.05055095782694119 \n",
            "\n",
            "Traing Time (in minutes)= 2.729242829481761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjLTWrM3_uKA",
        "outputId": "f88aa95a-edb2-4db7-dd4a-8c262ae6979e"
      },
      "source": [
        "#testing and evaluation\n",
        "img = images[0].view(1,784)\n",
        "\n",
        "with torch.no_grad():\n",
        "  logps = model(img)\n",
        "ps = torch.exp(logps)\n",
        "probab = list(ps.numpy()[0])\n",
        "print(\"predicted digit \", probab.index(max(probab)))\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predicted digit  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF-PT9aQFFx5",
        "outputId": "a9d0c87e-b15d-4921-9644-bdf99c7b5c32"
      },
      "source": [
        "correct_count, all_count = 0, 0\n",
        "for images,labels in valloader:\n",
        "  for i in range(len(labels)):\n",
        "    img = images[i].view(1, 784)\n",
        "    with torch.no_grad():\n",
        "        logps = model(img)\n",
        "\n",
        "    \n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.numpy()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    true_label = labels.numpy()[i]\n",
        "    if(true_label == pred_label):\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number Of Images Tested = 10000\n",
            "\n",
            "Model Accuracy = 0.9741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vztgy42hFtha"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy6PZyRxFyeE"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSeRY4POFzMy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}